# ğŸ§  Big Data ETL Pipeline (PostgreSQL + Pandas + Python)

## ğŸ“‹ Overview
This project demonstrates a **simple but scalable ETL (Extract, Transform, Load)** pipeline using **Python**, **Pandas**, and **PostgreSQL**.

It reads a large CSV dataset (`sales_transactions_3200000.csv`), cleans and deduplicates the data in memory, fills in missing values, computes totals, and loads the cleaned dataset into a PostgreSQL table efficiently in batches.

---

## âš™ï¸ Features
âœ… Connects automatically to a PostgreSQL database  
âœ… Creates a target table if it doesnâ€™t exist  
âœ… Reads a multi-million-row CSV file using **pandas**  
âœ… Deduplicates records globally (in-memory)  
âœ… Fills missing numeric values with the **mean**, and text fields with the **mode**  
âœ… Recomputes `total = price Ã— quantity` when missing or incorrect  
âœ… Loads data efficiently in chunks using `psycopg2.extras.execute_batch()`  
âœ… Skips duplicate `transaction_id` values using `ON CONFLICT DO NOTHING`

---

## ğŸ“ Project Structure
